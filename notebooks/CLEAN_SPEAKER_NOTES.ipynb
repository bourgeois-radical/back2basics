{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e96d04f0",
   "metadata": {},
   "source": [
    "## Probability vs Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ffcb01",
   "metadata": {},
   "source": [
    "## Speaker Notes\n",
    "\n",
    "- Emphasize the distinction: probability asks \"what data would we see?\" while likelihood asks \"what parameters explain the data we saw?\"\n",
    "\n",
    "- In the probability case, $p$ is fixed (we know the coin is fair) and we're asking about random outcomes\n",
    "\n",
    "- In the likelihood case, the outcome is fixed (we observed 8/10 tails) and we're searching over possible $p$ values\n",
    "\n",
    "- The likelihood function $\\mathcal{L}(p)$ peaks at $p=0.8$ because that's the parameter value that maximizes the probability of observing exactly what we saw\n",
    "\n",
    "- This is why MLE gives $\\hat{p} = 8/10 = 0.8$ - it's simply the empirical frequency\n",
    "\n",
    "- Note that while $p=0.8$ is most likely, a fair coin ($p=0.5$) could still produce this outcome, just less frequently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d287456",
   "metadata": {},
   "source": [
    "## MLE or Maximum Likelihood Estimation\n",
    "\n",
    "**Which parameter maximizes the probability of the observed data?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d64dc5",
   "metadata": {},
   "source": [
    "## Log-Likelihood\n",
    "\n",
    "Warum?\n",
    "\n",
    "The likelihood is the product of densities:\n",
    "\n",
    "**SAY: \"For 40 data points, you're multiplying 40 numbers each less than 1. This gets astronomically small — computers can't handle it.\"**\n",
    "\n",
    "### Underflow: The Technical Details\n",
    "\n",
    "| Type | Bits | Smallest Number |\n",
    "|------|------|-----------------|\n",
    "| float32 | 32 (1 sign, 8 exp, 23 mantissa) | ~10⁻³⁸ |\n",
    "| float64 | 64 (1 sign, 11 exp, 52 mantissa) | ~10⁻³⁰⁸ |\n",
    "\n",
    "**Why not just use float64?**\n",
    "- 2× memory, 2× slower on GPUs\n",
    "- Deep learning uses float32 or even float16\n",
    "- Still fails: n=1000 → likelihood can be 10⁻⁵⁰⁰\n",
    "\n",
    "**SAY: \"Likelihood shrinks exponentially with sample size. No floating point format saves you.\"**\n",
    "\n",
    "**Solution:** Log turns products into sums:\n",
    "\n",
    "$$\\ell(\\mu, \\sigma) = \\log L = \\sum_{i=1}^{n} \\log f(x_i \\mid \\mu, \\sigma)$$\n",
    "\n",
    "**SAY: \"Log is strictly increasing, so maximizing log-likelihood gives us the same answer as maximizing likelihood.\"**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887b39b8",
   "metadata": {},
   "source": [
    "## MLE Derivation for Normal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509301c1",
   "metadata": {},
   "source": [
    "## Speaker Notes\n",
    "\n",
    "**MLE and Loss Functions:**\n",
    "- The assumed error distribution determines the loss function: Gaussian → MSE (mean), Laplace → MAE (median)\n",
    "- Both distributions are symmetric (mean = median = mode in population), but MLE mechanics differ due to their probability densities\n",
    "- Gaussian penalizes quadratic deviations → sample mean minimizes MSE\n",
    "- Laplace penalizes linear deviations → sample median minimizes MAE\n",
    "- Using median for Gaussian data is valid but statistically less efficient than MLE\n",
    "\n",
    "**Sample Statistics:**\n",
    "- Population parameter $\\mu$ is unknown; we estimate it with sample statistic $\\bar{x} = \\frac{1}{n}\\sum x_i$\n",
    "- **LLN:** $\\bar{x} \\to \\mu$ as $n \\to \\infty$ (consistency)\n",
    "- **CLT:** Distribution of $\\bar{x}$ approaches $\\mathcal{N}(\\mu, \\sigma^2/n)$ regardless of original distribution\n",
    "- For small samples from Normal: $\\bar{x} \\approx \\text{median} \\approx \\text{mode}$, but not exact equality\n",
    "- For skewed distributions: mean ≠ median even in population (e.g., exponential, log-normal)\n",
    "\n",
    "**Practice:**\n",
    "1. Visualize data distribution (histograms, Q-Q plots)\n",
    "2. Make distributional assumption based on data characteristics\n",
    "3. Choose loss function matching assumption (MSE for Gaussian, MAE for Laplace/outliers)\n",
    "4. Remember: MLE under Gaussian assumption gives $\\hat{\\mu}_{\\text{MLE}} = \\bar{x}$, which is exactly what linear regression with MSE does\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bf71c5",
   "metadata": {},
   "source": [
    "### Why Smaller Residuals → Bigger Likelihood\n",
    "\n",
    "From the log-likelihood:\n",
    "\n",
    "$$\\ell = -n\\log(\\sigma) - \\frac{n}{2}\\log(2\\pi) - \\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(y_i - w^T x_i)^2$$\n",
    "\n",
    "The sum of squared residuals appears with a **negative coefficient**: $-\\frac{1}{2\\sigma^2}$\n",
    "\n",
    "When $\\sum (y_i - w^T x_i)^2$ is **smaller**:\n",
    "- The term $-\\frac{1}{2\\sigma^2}\\sum (y_i - w^T x_i)^2$ becomes **less negative** (closer to 0)\n",
    "- Therefore $\\ell$ becomes **larger** (maximized)\n",
    "\n",
    "**Example:**\n",
    "- If $\\sum (y_i - w^T x_i)^2 = 100$: $\\ell = \\text{const} - 50$ \n",
    "- If $\\sum (y_i - w^T x_i)^2 = 10$: $\\ell = \\text{const} - 5$ ✓ (larger!)\n",
    "\n",
    "Small errors → high probability of observing data → high likelihood!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555d7711",
   "metadata": {},
   "source": [
    "### Note on Bias\n",
    "\n",
    "The MLE estimator $\\hat{\\sigma}^2$ divides by $n$, not $n-1$.\n",
    "\n",
    "- MLE is **biased**: $E[\\hat{\\sigma}^2] = \\frac{n-1}{n}\\sigma^2$\n",
    "- The unbiased estimator uses $n-1$ (Bessel's correction)\n",
    "\n",
    "For large $n$, the difference is negligible. MLE optimizes likelihood, not unbiasedness.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fd1c20",
   "metadata": {},
   "source": [
    "## Speaker Notes: MLE Bias and Bessel's Correction\n",
    "\n",
    "**Why MLE is biased:**\n",
    "- MLE gives $\\hat{\\sigma}^2_{\\text{MLE}} = \\frac{1}{n}\\sum(x_i - \\bar{x})^2$\n",
    "- The true expected value is $E[\\hat{\\sigma}^2_{\\text{MLE}}] = \\frac{n-1}{n}\\sigma^2$, which is slightly less than $\\sigma^2$\n",
    "- This happens because we use sample mean $\\bar{x}$ instead of true mean $\\mu$, which reduces variability\n",
    "\n",
    "**Bessel's correction:**\n",
    "- Unbiased estimator: $s^2 = \\frac{1}{n-1}\\sum(x_i - \\bar{x})^2$\n",
    "- We \"lose one degree of freedom\" by estimating $\\mu$ from data\n",
    "- Now $E[s^2] = \\sigma^2$ (unbiased)\n",
    "\n",
    "**In practice:**\n",
    "- For $n=100$: bias is $\\frac{99}{100} = 0.99$ (1% difference)\n",
    "- For $n=1000$: bias is $\\frac{999}{1000} = 0.999$ (0.1% difference)\n",
    "- Most ML uses large datasets, so the bias is negligible\n",
    "- MLE maximizes likelihood (not unbiasedness), which is why it divides by $n$\n",
    "\n",
    "**Key insight:** MLE doesn't care about unbiasedness - it only cares about what parameter values make the observed data most probable.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b7680d",
   "metadata": {},
   "source": [
    "## Speaker Notes: Where $E[s^2] = \\sigma^2$ Comes From\n",
    "\n",
    "**The math:**\n",
    "\n",
    "Starting with $\\sum(x_i - \\bar{x})^2$, it can be shown that:\n",
    "\n",
    "$$E\\left[\\sum_{i=1}^{n}(x_i - \\bar{x})^2\\right] = (n-1)\\sigma^2$$\n",
    "\n",
    "This is because:\n",
    "- We have $n$ observations\n",
    "- But $\\bar{x}$ is calculated from the same data, creating a constraint\n",
    "- Only $(n-1)$ values are \"free\" to vary (degrees of freedom)\n",
    "\n",
    "Therefore:\n",
    "\n",
    "$$E\\left[\\frac{1}{n-1}\\sum_{i=1}^{n}(x_i - \\bar{x})^2\\right] = E[s^2] = \\sigma^2$$\n",
    "\n",
    "**Why $n-1$?** When we estimate $\\mu$ with $\\bar{x}$, we've \"used up\" one piece of information from our data. The last observation is determined once you know the first $(n-1)$ and the mean.\n",
    "\n",
    "**Contrast with MLE:**\n",
    "\n",
    "$$E\\left[\\frac{1}{n}\\sum_{i=1}^{n}(x_i - \\bar{x})^2\\right] = \\frac{n-1}{n}\\sigma^2 < \\sigma^2 \\text{ (biased)}$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf25150b",
   "metadata": {},
   "source": [
    "## Derivation: Why $E[\\sum(x_i - \\bar{x})^2] = (n-1)\\sigma^2$\n",
    "\n",
    "**Start with the sum of squared deviations from sample mean:**\n",
    "\n",
    "$$\\sum_{i=1}^{n}(x_i - \\bar{x})^2$$\n",
    "\n",
    "**Trick: Add and subtract the true mean $\\mu$:**\n",
    "\n",
    "$$\\sum_{i=1}^{n}(x_i - \\bar{x})^2 = \\sum_{i=1}^{n}[(x_i - \\mu) - (\\bar{x} - \\mu)]^2$$\n",
    "\n",
    "**Expand the square:**\n",
    "\n",
    "$$= \\sum_{i=1}^{n}[(x_i - \\mu)^2 - 2(x_i - \\mu)(\\bar{x} - \\mu) + (\\bar{x} - \\mu)^2]$$\n",
    "\n",
    "**Split into three sums:**\n",
    "\n",
    "$$= \\sum_{i=1}^{n}(x_i - \\mu)^2 - 2(\\bar{x} - \\mu)\\sum_{i=1}^{n}(x_i - \\mu) + \\sum_{i=1}^{n}(\\bar{x} - \\mu)^2$$\n",
    "\n",
    "**Simplify middle term:**\n",
    "\n",
    "$$\\sum_{i=1}^{n}(x_i - \\mu) = \\sum_{i=1}^{n}x_i - n\\mu = n\\bar{x} - n\\mu = n(\\bar{x} - \\mu)$$\n",
    "\n",
    "So: $-2(\\bar{x} - \\mu) \\cdot n(\\bar{x} - \\mu) = -2n(\\bar{x} - \\mu)^2$\n",
    "\n",
    "**Simplify last term:**\n",
    "\n",
    "$$\\sum_{i=1}^{n}(\\bar{x} - \\mu)^2 = n(\\bar{x} - \\mu)^2$$\n",
    "\n",
    "**Combine:**\n",
    "\n",
    "$$\\sum_{i=1}^{n}(x_i - \\bar{x})^2 = \\sum_{i=1}^{n}(x_i - \\mu)^2 - 2n(\\bar{x} - \\mu)^2 + n(\\bar{x} - \\mu)^2$$\n",
    "\n",
    "$$= \\sum_{i=1}^{n}(x_i - \\mu)^2 - n(\\bar{x} - \\mu)^2$$\n",
    "\n",
    "**Take expectation of both sides:**\n",
    "\n",
    "$$E\\left[\\sum_{i=1}^{n}(x_i - \\bar{x})^2\\right] = E\\left[\\sum_{i=1}^{n}(x_i - \\mu)^2\\right] - E[n(\\bar{x} - \\mu)^2]$$\n",
    "\n",
    "**First term:**\n",
    "\n",
    "$$E\\left[\\sum_{i=1}^{n}(x_i - \\mu)^2\\right] = n \\cdot E[(x_i - \\mu)^2] = n\\sigma^2$$\n",
    "\n",
    "**Second term (using $\\text{Var}(\\bar{x}) = \\frac{\\sigma^2}{n}$):**\n",
    "\n",
    "$$E[n(\\bar{x} - \\mu)^2] = n \\cdot \\text{Var}(\\bar{x}) = n \\cdot \\frac{\\sigma^2}{n} = \\sigma^2$$\n",
    "\n",
    "**Final result:**\n",
    "\n",
    "$$E\\left[\\sum_{i=1}^{n}(x_i - \\bar{x})^2\\right] = n\\sigma^2 - \\sigma^2 = (n-1)\\sigma^2$$\n",
    "\n",
    "**Therefore:**\n",
    "\n",
    "$$E\\left[\\frac{1}{n-1}\\sum_{i=1}^{n}(x_i - \\bar{x})^2\\right] = \\sigma^2 \\quad \\text{(unbiased)}$$\n",
    "\n",
    "$$E\\left[\\frac{1}{n}\\sum_{i=1}^{n}(x_i - \\bar{x})^2\\right] = \\frac{n-1}{n}\\sigma^2 \\quad \\text{(biased)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd25314",
   "metadata": {},
   "source": [
    "**Why MSE uses $\\frac{1}{n}$, not $\\frac{1}{n-1}$:**\n",
    "\n",
    "1. **MSE is for optimization, not estimation:**\n",
    "   - We're minimizing $\\frac{1}{n}\\sum(y_i - \\hat{y}_i)^2$ to find best $w$\n",
    "   - The $\\frac{1}{n}$ is just for averaging—it doesn't affect which $w$ minimizes it\n",
    "   - Scaling by $\\frac{1}{n}$ vs $\\frac{1}{n-1}$ doesn't change the optimal $w$\n",
    "\n",
    "2. **We're not estimating population variance:**\n",
    "   - In statistics, we estimate $\\sigma^2$ from a sample → use $n-1$ for unbiasedness\n",
    "   - In ML, we're minimizing training error → just want average loss per sample\n",
    "\n",
    "3. **Practical reason:**\n",
    "   - $\\frac{1}{n}$ is the true average loss per sample\n",
    "   - Makes metrics comparable across different dataset sizes\n",
    "   - $\\text{MSE} = 0.5$ means \"average squared error is 0.5 per example\"\n",
    "\n",
    "**Bottom line:** Bessel's correction matters when you're doing statistical inference (estimating $\\sigma^2$). For loss functions, we just want the mean—bias doesn't matter because we're optimizing, not estimating population parameters.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5e701e",
   "metadata": {},
   "source": [
    "## While training with MSE, we're minimizing the **empirical variance of residuals** (on our training data), which under the Gaussian assumption corresponds to maximizing likelihood.\n",
    "\n",
    "$$\\text{MSE} = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - w^T x_i)^2$$\n",
    "\n",
    "This is:\n",
    "- The sample variance of residuals (if mean residual ≈ 0)\n",
    "- MLE estimate $\\hat{\\sigma}^2$ under Gaussian noise assumption\n",
    "- NOT estimating the true population variance $\\sigma^2$ (that would need $n-1$)\n",
    "\n",
    "**What we're really doing:**\n",
    "- Finding $w$ that makes residuals as small as possible\n",
    "- Equivalently: minimizing the spread/variance of prediction errors\n",
    "- Under Gaussian assumption: maximizing likelihood\n",
    "\n",
    "**So yes, you can say:** \"MSE training minimizes the variance of residuals on the training set.\"\n",
    "\n",
    "But remember: it's the *empirical* variance (biased estimator), not an unbiased estimate of population variance.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8805062",
   "metadata": {},
   "source": [
    "# Bias-Variance trade-off"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb780a5",
   "metadata": {},
   "source": [
    "\n",
    "**Bias is unknowable in practice** because we don't have access to $f_{\\text{true}}(x)$. **If we knew the true function, we wouldn't need to build a model in the first place!** The term $(f_{\\text{true}}(x) - \\mathbb{E}[\\hat{f}(x)])^2$ is a theoretical quantity that helps us understand what's happening conceptually, but we can never actually compute it with real data. We're always in the dark about how much bias our model has. We can suspect it based on things like underfitting on the training set, or we can reason about it based on our choice of model family (linear models probably have high bias for complex relationships), but we can never measure it directly.\n",
    "\n",
    "**Variance is estimable in practice** because it only requires comparing different models to each other, not to the unknowable truth. If you train multiple models on different training sets (or different bootstrap samples, or different cross-validation folds), you can measure how much the predictions vary. This is something we can actually observe and quantify.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fe4a8f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Why expected? \n",
    "\n",
    "Because any single training set is random luck. You need to know how your model performs on average across all possible training sets you could have collected. One dataset might make your model look great, another terrible. The expectation tells you the true typical performance.\n",
    "\n",
    "\n",
    "## Why squared? \n",
    "\n",
    "Because we care about error magnitude regardless of direction (being off by +5 or -5 is equally bad), and squaring has nice mathematical properties that make the decomposition possible. Also penalizes large errors more heavily.\n",
    "Together: \"How wrong is my model typically, across all possible training scenarios?\" That's what you actually care about for choosing modeling approaches.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d97390e",
   "metadata": {},
   "source": [
    "## Speaker Notes: Understanding Each Term\n",
    "\n",
    "### Term 1: Why does $\\mathbb{E}[\\varepsilon^2] = \\sigma^2$?\n",
    "\n",
    "This question often causes confusion because people think \"if the expected value of noise is zero, doesn't that mean there's no noise?\" Let me clarify what zero mean actually means and why there's still plenty of noise present.\n",
    "\n",
    "When we say $\\mathbb{E}[\\varepsilon] = 0$, we're saying that if you average the noise across infinitely many observations, the positive and negative fluctuations cancel out perfectly. The noise doesn't systematically push predictions in one direction. Sometimes the noise adds to the true value, sometimes it subtracts, but on average these effects balance to zero.\n",
    "\n",
    "But this absolutely does not mean that the noise is zero for any particular observation. For any single data point, the noise $\\varepsilon$ is almost certainly non-zero. It might be plus three, or minus two point five, or plus zero point seven. The noise is very much present and very much affecting individual predictions. It's just that when you step back and look at the big picture across many observations, the ups and downs average out.\n",
    "\n",
    "Think of it like this. Imagine you're measuring the height of a door frame with a slightly bent ruler. Sometimes the bend causes you to measure too high by two centimeters, sometimes too low by three centimeters, sometimes too high by one centimeter. Each individual measurement has error - real, concrete error that affects that measurement. But if you measure many times and the ruler bends randomly in different directions, your measurement errors might average to zero. That doesn't mean your ruler is straight or that there's no measurement error. It means the errors don't have a systematic bias in one direction.\n",
    "\n",
    "The variance $\\sigma^2$ quantifies how much this noise typically deviates from its mean of zero. Even though the noise averages to zero, individual noise values are scattered around zero, and variance measures the magnitude of that scatter. A small variance means the noise values are clustered tightly near zero (measurements are consistently close to truth). A large variance means the noise values are spread widely around zero (measurements vary wildly from truth).\n",
    "\n",
    "Here's the mathematical unpacking. For any random variable $Z$ with mean $\\mu$, variance is defined as:\n",
    "\n",
    "$$\\text{Var}(Z) = \\mathbb{E}[(Z - \\mu)^2]$$\n",
    "\n",
    "This measures the expected squared distance from the mean. For our noise term $\\varepsilon$, the mean is zero:\n",
    "\n",
    "$$\\mathbb{E}[\\varepsilon] = 0$$\n",
    "\n",
    "So when we compute the variance of noise:\n",
    "\n",
    "$$\\text{Var}(\\varepsilon) = \\mathbb{E}[(\\varepsilon - 0)^2] = \\mathbb{E}[\\varepsilon^2]$$\n",
    "\n",
    "We specified in our setup that the noise has variance $\\sigma^2$. This is an assumption we're making about how noisy the world is. Therefore:\n",
    "\n",
    "$$\\mathbb{E}[\\varepsilon^2] = \\text{Var}(\\varepsilon) = \\sigma^2$$\n",
    "\n",
    "What this equation is really saying is that if you take many observations, square all the noise terms (so they're all positive and you can't have cancellation), and average those squared values, you get $\\sigma^2$. This is the irreducible error in your predictions. Even with a perfect model, individual predictions will still be wrong by roughly plus or minus the square root of sigma squared, because that's how much the world randomly fluctuates around the truth.\n",
    "\n",
    "So to directly answer the concern: saying the expected value of noise is zero does not mean there is no noise. It means the noise is unbiased - it doesn't systematically distort things in one direction. But individual observations are still corrupted by noise, and the variance sigma squared tells us how severe that corruption typically is. This irreducible error of sigma squared is the baseline level of wrongness we cannot escape, no matter how perfect our model becomes.\n",
    "### Term 2: Why does $2\\mathbb{E}[\\varepsilon(f_{\\text{true}}(x) - \\hat{f}(x))] = 0$?\n",
    "\n",
    "This term involves the product of noise and model error. It equals zero for two important reasons that work together.\n",
    "\n",
    "First, the noise $\\varepsilon$ has expected value zero. On average, across many observations, positive noise and negative noise cancel out. This means $\\mathbb{E}[\\varepsilon] = 0$.\n",
    "\n",
    "Second, the noise $\\varepsilon$ is independent of our model $\\hat{f}(x)$. The random fluctuation in any particular observation doesn't depend on which training set we used to build our model. They're separate sources of randomness.\n",
    "\n",
    "When two random variables are independent and one has mean zero, their product has expected value zero. Here's why:\n",
    "\n",
    "$$\\mathbb{E}[\\varepsilon \\cdot (f_{\\text{true}}(x) - \\hat{f}(x))] = \\mathbb{E}[\\varepsilon] \\cdot \\mathbb{E}[f_{\\text{true}}(x) - \\hat{f}(x)]$$\n",
    "\n",
    "The first factor is $\\mathbb{E}[\\varepsilon] = 0$. Therefore the whole product is zero:\n",
    "\n",
    "$$= 0 \\cdot \\mathbb{E}[f_{\\text{true}}(x) - \\hat{f}(x)] = 0$$\n",
    "\n",
    "So our middle term becomes:\n",
    "\n",
    "$$2\\mathbb{E}[\\varepsilon(f_{\\text{true}}(x) - \\hat{f}(x))] = 2 \\cdot 0 = 0$$\n",
    "\n",
    "This cross-term vanishes completely. The noise and the model error don't interact - they contribute to total error independently and additively.\n",
    "\n",
    "### Term 3: What about $\\mathbb{E}[(f_{\\text{true}}(x) - \\hat{f}(x))^2]$?\n",
    "\n",
    "This term measures the expected squared model error. Unlike the other terms, this one doesn't simplify immediately. It captures how wrong our model is on average. This is the term we'll decompose further in the next steps to separate bias from variance.\n",
    "\n",
    "---\n",
    "\n",
    "## After Simplification\n",
    "\n",
    "After applying these simplifications, we have:\n",
    "\n",
    "$$\\mathbb{E}[(y - \\hat{f}(x))^2] = \\sigma^2 + \\mathbb{E}[(f_{\\text{true}}(x) - \\hat{f}(x))^2]$$\n",
    "\n",
    "The first term $\\sigma^2$ is the irreducible error - the noise we cannot eliminate. The second term captures all the error that comes from our model being imperfect. Our next job is to understand what's inside that second term by breaking it into bias and variance components.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706c1162",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
